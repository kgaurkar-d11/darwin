{{- if .Values.modelCache.enabled }}
{{/*
================================================================================
MODEL CACHING ARCHITECTURE
================================================================================

This template manages model download and caching for ML deployments.
Two strategies are supported: emptydir (per-pod) and pvc (shared cache).

ARCHITECTURE OVERVIEW:
┌─────────────────────────────────────────────────────────────────────────┐
│ EMPTYDIR STRATEGY (Small Models <1GB)                                   │
├─────────────────────────────────────────────────────────────────────────┤
│  1. Init Container (per pod):                                           │
│     - Runs download_model_emptydir.py                                   │
│     - Downloads model to pod-local emptyDir volume "model-storage"      │
│     - Model at path: /model-cache/                                      │
│  2. Main Container:                                                     │
│     - Mounts same "model-storage" volume (readOnly)                     │
│     - Reads model from: /model-cache/                                   │
│  3. Lifecycle: Model deleted when pod terminates                        │
├─────────────────────────────────────────────────────────────────────────┤
│ PVC STRATEGY (Large Models ≥1GB)                                        │
├─────────────────────────────────────────────────────────────────────────┤
│  1. Download Job (runs in parallel, non-blocking):                      │
│     - Runs download_model.py as regular Job (NOT a Helm hook)          │
│     - Downloads model to shared PVC "model-cache"                       │
│     - Model at path: /model-cache/<cache-key>/                          │
│     - Helm returns immediately without waiting                          │
│  2. Init Container (per pod):                                           │
│     - Waits for download job to complete                                │
│     - Checks if model exists at /model-cache/<cache-key>/MLmodel       │
│     - Proceeds once model is available                                  │
│  3. Main Container (all pods):                                          │
│     - Mounts "model-cache" PVC (readOnly)                               │
│     - Reads model from: /model-cache/<cache-key>/                       │
│  4. Lifecycle: Model persists across pod restarts and deployments       │
└─────────────────────────────────────────────────────────────────────────┘

VOLUME NAMING:
  - "model-storage" = emptyDir volume (per-pod, temporary)
  - "model-cache" = PVC volume (shared, persistent)
  
Different names are required because Kubernetes volumes cannot conditionally
change type. Each strategy uses its appropriate volume type and name.

CACHE KEY:
  - Format: SHA256(deploymentName:modelUri)
  - Purpose: Allows multiple deployments to share same PVC safely
  - Example: /model-cache/47645fcee5596c6f7ddea5b80b572fa8/MLmodel

RESOURCES DEFINED HERE:
  1. PVC: Shared model cache (pvc strategy only, auto-created per namespace)
  2. ConfigMap: Download scripts for both strategies
  3. Job: Pre-deployment model download (pvc strategy only)
================================================================================
*/}}
{{- if eq .Values.modelCache.strategy "pvc" }}
{{- $pvcName := .Values.modelCache.pvcName | default "ml-model-cache" }}
{{- $existingPVC := lookup "v1" "PersistentVolumeClaim" .Release.Namespace $pvcName }}
{{- if and .Values.global (index .Values.global "local-k8s") (not $existingPVC) }}
---
# PersistentVolume for local-k8s (Kind) clusters only
# In production, use a dynamic provisioner that supports ReadWriteMany
apiVersion: v1
kind: PersistentVolume
metadata:
  # PV name includes namespace to allow multiple namespaces to have their own PV
  name: {{ $pvcName }}-{{ .Release.Namespace }}
  labels:
    app.kubernetes.io/component: model-cache
    app.kubernetes.io/part-of: darwin
    darwin.namespace: {{ .Release.Namespace }}
spec:
  storageClassName: {{ .Values.modelCache.storageClassName | default "shared-services" }}
  capacity:
    storage: {{ .Values.modelCache.size | default "50Gi" }}
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Retain
  hostPath:
    path: /mnt/shared-data/model-cache/{{ .Release.Namespace }}
    type: DirectoryOrCreate
{{- end }}
{{- if not $existingPVC }}
---
# PersistentVolumeClaim for shared model cache
# 
# IMPORTANT: This PVC is NAMESPACE-SCOPED and shared by ALL deployments in this namespace
# - First deployment in a namespace creates it
# - Subsequent deployments reuse it (lookup check prevents recreation)
# - All model deployments in same namespace share this cache
#
# This PVC is only created if it doesn't already exist (checked via Helm lookup function)
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: {{ $pvcName }}
  namespace: {{ .Release.Namespace }}
  labels:
    app.kubernetes.io/component: model-cache
    app.kubernetes.io/part-of: darwin
    darwin.cache-type: shared-model-cache
  annotations:
    darwin.io/description: "Shared model cache for all ML deployments in {{ .Release.Namespace }} namespace"
    helm.sh/resource-policy: keep  # Prevent Helm from deleting PVC on uninstall - preserve cached models
spec:
  accessModes:
    - ReadWriteMany  # Required: multiple pods need concurrent access
  resources:
    requests:
      storage: {{ .Values.modelCache.size | default "50Gi" }}
  {{- if and .Values.global (index .Values.global "local-k8s") }}
  storageClassName: {{ .Values.modelCache.storageClassName | default "shared-services" }}
  volumeName: {{ $pvcName }}-{{ .Release.Namespace }}
  {{- else }}
  {{- if .Values.modelCache.storageClassName }}
  storageClassName: {{ .Values.modelCache.storageClassName }}
  {{- end }}
  {{- end }}
{{- else }}
# PVC {{ $pvcName }} already exists in namespace {{ .Release.Namespace }}, skipping creation
{{- end }}
{{- end }}
---
# ConfigMap containing model download scripts for both strategies
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "service-deployment.fullname" . }}-model-downloader
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "service-deployment.labels" . | nindent 4 }}
    app.kubernetes.io/component: model-cache
data:
  # Pre-deploy job script (for pvc strategy)
  download_model.py: |
{{ .Files.Get "scripts/download_model.py" | indent 4 }}
  # Init container script (for emptydir strategy)
  download_model_emptydir.py: |
{{ .Files.Get "scripts/download_model_emptydir.py" | indent 4 }}
  # Shared utility module
  model_utils.py: |
{{ .Files.Get "scripts/model_utils.py" | indent 4 }}
  # Cache cleanup script (for CronJob)
  cleanup_cache.py: |
{{ .Files.Get "scripts/cleanup_cache.py" | indent 4 }}
---
# Model Download Job for PVC strategy
# Runs in parallel with deployment (NOT a Helm hook) for fast API response
# Deployment pods wait via init container until model is cached
{{- if eq .Values.modelCache.strategy "pvc" }}
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ template "service-deployment.fullname" . }}-model-download
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "service-deployment.labels" . | nindent 4 }}
    app.kubernetes.io/component: model-download
  annotations:
    # Note: NOT a Helm hook - runs in parallel with deployment for fast API response
    # The deployment pods will wait via init container readiness until model is cached
    "helm.sh/resource-policy": keep
spec:
  # Retry up to 3 times if download fails
  backoffLimit: 3
  # Fail fast if job takes longer than 10 minutes (prevents hanging deployments)
  activeDeadlineSeconds: 600
  # Clean up completed jobs after 1 hour
  ttlSecondsAfterFinished: 3600
  template:
    metadata:
      labels:
        {{- include "service-deployment.selectorLabels" . | nindent 8 }}
        app.kubernetes.io/component: model-download
    spec:
      restartPolicy: OnFailure
      serviceAccountName: darwin
      containers:
      - name: model-downloader
        image: {{ .Values.modelCache.downloaderImage }}
        command:
          - python
          - /scripts/download_model.py
        env:
          - name: MODEL_URI
            value: "{{ .Values.modelCache.modelUri }}"
          - name: CACHE_PATH
            value: "{{ .Values.modelCache.cachePath }}"
          - name: DEPLOYMENT_NAME
            value: "{{ template "service-deployment.fullname" . }}"
          - name: MAX_RETRIES
            value: "{{ .Values.modelCache.maxRetries | default 5 }}"
          - name: BACKOFF_SECONDS
            value: "{{ .Values.modelCache.backoffSeconds | default 10 }}"
          - name: MLFLOW_TRACKING_URI
            valueFrom:
              secretKeyRef:
                name: {{ template "service-deployment.fullname" . }}-mlflow-creds
                key: tracking-uri
                optional: false
          - name: MLFLOW_TRACKING_USERNAME
            valueFrom:
              secretKeyRef:
                name: {{ template "service-deployment.fullname" . }}-mlflow-creds
                key: username
                optional: true
          - name: MLFLOW_TRACKING_PASSWORD
            valueFrom:
              secretKeyRef:
                name: {{ template "service-deployment.fullname" . }}-mlflow-creds
                key: password
                optional: true
        resources:
          {{- toYaml .Values.modelCache.resources | nindent 10 }}
        volumeMounts:
          - name: model-downloader-script
            mountPath: /scripts
            readOnly: true
          - name: model-cache
            mountPath: {{ .Values.modelCache.cachePath }}
      volumes:
        - name: model-downloader-script
          configMap:
            name: {{ template "service-deployment.fullname" . }}-model-downloader
            defaultMode: 0755
        - name: model-cache
          persistentVolumeClaim:
            claimName: {{ .Values.modelCache.pvcName }}
{{- end }}
{{- end }}

