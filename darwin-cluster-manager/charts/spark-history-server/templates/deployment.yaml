apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "spark-history-server.fullname" . }}
  labels:  {{ include "spark-history-server.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ include "spark-history-server.name" . }}
      app.kubernetes.io/instance: {{ .Release.Name }}
  template:
    metadata:
      labels: {{ include "spark-history-server.labels" . | nindent 8 }}
      {{- if .Values.podAnnotations }}
      annotations: {{ toYaml .Values.podAnnotations | nindent 8 }}
      {{- end }}
    spec:
      serviceAccountName: {{ include "spark-history-server.serviceAccountName" . }}
      containers:
      - name: {{ .Chart.Name }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        env:
        - name: SPARK_NO_DAEMONIZE
          value: "true"
        ports:
        - name: history-port
          containerPort: 18080
          protocol: TCP
        resources: {{ toYaml .Values.resources | nindent 10 }}
        command:
        - "/bin/sh"
        - "-c"
        - >
          if [ "$enablePVC" == "true" ]; then
            export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
            -Dspark.history.fs.logDirectory=file:/data/$eventsDir";
          elif [ "$enableGCS" == "true" ]; then
            export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
            -Dspark.history.fs.logDirectory=$logDirectory";
            if [ "$enableIAM" == "false" ]; then
              export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.hadoop.google.cloud.auth.service.account.json.keyfile=/etc/secrets/$key";
            fi;
          elif [ "$enableS3" == "true" ]; then
            export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.history.fs.logDirectory=$logDirectory \
              -Dspark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem";
            if [ -n "$endpoint" ] && [ "$endpoint" != "default" ]; then
              export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.hadoop.fs.s3a.endpoint=$endpoint";
            fi;
            if [ "$enableIAM" == "false" ]; then
              export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.hadoop.fs.s3a.access.key=$(cat /etc/secrets/${accessKeyName}) \
              -Dspark.hadoop.fs.s3a.secret.key=$(cat /etc/secrets/${secretKeyName})";
            else
              export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
              -Dspark.hadoop.fs.s3a.aws.credentials.provider=com.amazonaws.auth.WebIdentityTokenCredentialsProvider \
              -Dspark.hadoop.fs.s3a.credentialsType=AssumeRole";
            fi;
          else
            export SPARK_HISTORY_OPTS="$SPARK_HISTORY_OPTS \
            -Dspark.history.fs.logDirectory=$logDirectory";
          fi;
          /spark/sbin/start-history-server.sh;
        envFrom:
        - configMapRef:
            name: {{ include "spark-history-server.fullname" . }}
        livenessProbe:
          httpGet:
            path: /
            port: history-port
        readinessProbe:
          httpGet:
            path: /
            port: history-port
        {{- if .Values.pvc.enablePVC }}
        volumeMounts:
        - name: data
          mountPath: /data
        {{- else if .Values.gcs.enableGCS }}
        {{- if (not .Values.gcs.enableIAM) }}
        volumeMounts:
        - name: secrets-volume
          mountPath: /etc/secrets
        {{- end }}
        {{- else if .Values.s3.enableS3 }}
        {{- if (not .Values.s3.enableIAM) }}
        volumeMounts:
        - name: secrets-volume
          mountPath: /etc/secrets
        {{- end }}
        {{- else }}
        volumeMounts:
        - name: core-site
          mountPath: /etc/hadoop/core-site.xml
          subPath: core-site.xml
        - name: hdfs-site
          mountPath: /etc/hadoop/hdfs-site.xml
          subPath: hdfs-site.xml
        {{- end }}
      {{- if .Values.pvc.enablePVC }}
      volumes:
      - name: data
        persistentVolumeClaim:
          claimName: {{ .Values.pvc.existingClaimName }}
      {{- else if .Values.gcs.enableGCS }}
      {{- if (not .Values.gcs.enableIAM) }}
      volumes:
      - name: secrets-volume
        secret:
          secretName: {{ .Values.gcs.secret }}
      {{- end }}
      {{- else if .Values.s3.enableS3 }}
      {{- if (not .Values.s3.enableIAM) }}
      volumes:
      - name: secrets-volume
        secret:
          secretName: {{ .Values.s3.secret }}
      {{- end }}
      {{- end }}
    {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
    {{- end }}
    {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
    {{- end }}
    {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
    {{- end }}
    {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
    {{- end }}
