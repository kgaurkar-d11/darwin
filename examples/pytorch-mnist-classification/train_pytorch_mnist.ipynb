{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MNIST Digit Classification with PyTorch\n",
        "\n",
        "This notebook trains a neural network using PyTorch to classify handwritten digits.\n",
        "\n",
        "**Dataset**: MNIST Handwritten Digits\n",
        "- 60,000 training samples, 10,000 test samples\n",
        "- Target: Digit class (0-9)\n",
        "\n",
        "**Features**:\n",
        "- 28x28 grayscale images (784 pixels)\n",
        "- Normalized pixel values (0-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
        "%pip install pandas numpy scikit-learn mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Force CPU-only execution (disable CUDA even if available)\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
        "\n",
        "# ============================================================================\n",
        "# Standard imports (after environment configuration)\n",
        "# ============================================================================\n",
        "import argparse\n",
        "import json\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# PyTorch imports (CPU-only)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Set default tensor type to CPU\n",
        "torch.set_default_dtype(torch.float32)\n",
        "device = torch.device('cpu')\n",
        "\n",
        "# Verify PyTorch configuration\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# MLflow imports\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "from mlflow import set_tracking_uri, set_experiment\n",
        "from mlflow.client import MlflowClient\n",
        "from mlflow.models.signature import infer_signature\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_mlflow(mlflow_uri: str, username: str, password: str) -> MlflowClient:\n",
        "    \"\"\"Configure MLflow tracking and return client.\"\"\"\n",
        "    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = username\n",
        "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = password\n",
        "    \n",
        "    set_tracking_uri(mlflow_uri)\n",
        "    client = MlflowClient(mlflow_uri)\n",
        "    \n",
        "    print(f\"MLflow tracking URI: {mlflow_uri}\")\n",
        "    return client\n",
        "\n",
        "\n",
        "def load_and_prepare_data():\n",
        "    \"\"\"Load MNIST dataset using torchvision and prepare train/test splits.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"LOADING DATASET (torchvision MNIST)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Lambda(lambda x: x.view(-1))  # flatten 28x28 â†’ 784\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.MNIST(\n",
        "        root=\"./data\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    test_dataset = datasets.MNIST(\n",
        "        root=\"./data\",\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    print(\"MNIST download / load completed\")\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_train = train_dataset.data.numpy().reshape(-1, 784).astype('float32') / 255.0\n",
        "    y_train = train_dataset.targets.numpy()\n",
        "\n",
        "    X_test = test_dataset.data.numpy().reshape(-1, 784).astype('float32') / 255.0\n",
        "    y_test = test_dataset.targets.numpy()\n",
        "\n",
        "    # Use subset for faster training\n",
        "    X_train, y_train = X_train[:8000], y_train[:8000]\n",
        "    X_test, y_test = X_test[:2000], y_test[:2000]\n",
        "\n",
        "    print(f\"Dataset: MNIST\")\n",
        "    print(f\"Features: 784 (28x28 pixels)\")\n",
        "    print(f\"Classes: 10 (digits 0-9)\")\n",
        "    print(f\"\\nTrain samples: {len(X_train):,}\")\n",
        "    print(f\"Test samples: {len(X_test):,}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "\n",
        "class MNISTNet(nn.Module):\n",
        "    \"\"\"Simple neural network for MNIST classification.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(MNISTNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)  # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_model(X_train, y_train, X_test, y_test, hyperparams: dict):\n",
        "    \"\"\"Train PyTorch model and return predictions.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING MODEL\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    print(\"Hyperparameters:\")\n",
        "    for key, value in hyperparams.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    \n",
        "    # Convert to tensors\n",
        "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=hyperparams['batch_size'], shuffle=True)\n",
        "    \n",
        "    # Initialize model\n",
        "    model = MNISTNet()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'])\n",
        "    \n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(hyperparams['epochs']):\n",
        "        total_loss = 0\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{hyperparams['epochs']}], Loss: {total_loss/len(train_loader):.4f}\")\n",
        "    \n",
        "    print(\"Training completed!\")\n",
        "    \n",
        "    # Predictions\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_train_pred = torch.argmax(model(X_train_tensor), dim=1).numpy()\n",
        "        y_test_pred = torch.argmax(model(X_test_tensor), dim=1).numpy()\n",
        "    \n",
        "    return model, y_train_pred, y_test_pred\n",
        "\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, dataset_name=\"Test\"):\n",
        "    \"\"\"Calculate and return evaluation metrics.\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    \n",
        "    return {\n",
        "        f\"{dataset_name.lower()}_accuracy\": accuracy,\n",
        "        f\"{dataset_name.lower()}_precision\": precision,\n",
        "        f\"{dataset_name.lower()}_recall\": recall,\n",
        "        f\"{dataset_name.lower()}_f1\": f1\n",
        "    }\n",
        "\n",
        "\n",
        "def log_to_mlflow(model, X_train, y_train, X_test, y_test, \n",
        "                  y_train_pred, y_test_pred, hyperparams):\n",
        "    \"\"\"Log model, parameters, and metrics to MLflow.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"LOGGING TO MLFLOW\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Log hyperparameters\n",
        "    for key, value in hyperparams.items():\n",
        "        mlflow.log_param(key, value)\n",
        "    \n",
        "    # Calculate and log metrics\n",
        "    train_metrics = calculate_metrics(y_train, y_train_pred, \"Train\")\n",
        "    test_metrics = calculate_metrics(y_test, y_test_pred, \"Test\")\n",
        "    all_metrics = {**train_metrics, **test_metrics}\n",
        "    \n",
        "    for metric_name, metric_value in all_metrics.items():\n",
        "        mlflow.log_metric(metric_name, metric_value)\n",
        "    \n",
        "    print(\"\\nModel Performance:\")\n",
        "    print(f\"  Training Accuracy: {train_metrics['train_accuracy']:.4f}\")\n",
        "    print(f\"  Training F1: {train_metrics['train_f1']:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_metrics['test_accuracy']:.4f}\")\n",
        "    print(f\"  Test Precision: {test_metrics['test_precision']:.4f}\")\n",
        "    print(f\"  Test Recall: {test_metrics['test_recall']:.4f}\")\n",
        "    print(f\"  Test F1: {test_metrics['test_f1']:.4f}\")\n",
        "    \n",
        "    # Print confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_test_pred)\n",
        "    print(f\"\\n  Confusion Matrix (first 5x5):\")\n",
        "    print(f\"  {cm[:5, :5]}\")\n",
        "    \n",
        "    # Create input DataFrame with column names (for signature)\n",
        "    X_train_df = pd.DataFrame(X_train)\n",
        "    X_train_df.columns = [f\"pixel_{i}\" for i in range(X_train_df.shape[1])]\n",
        "    \n",
        "    # Create output DataFrame matching model's actual output (raw logits)\n",
        "    # MLflow's pytorch flavor returns raw model output, not argmax\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X_sample = torch.tensor(X_train[:1], dtype=torch.float32)\n",
        "        logits = model(X_sample).numpy()  # Shape: (1, 10) - raw scores for each class\n",
        "    \n",
        "    # Create DataFrame with one column per class (digit 0-9)\n",
        "    y_pred_df = pd.DataFrame(logits, columns=[f\"digit_{i}_score\" for i in range(10)])\n",
        "    \n",
        "    # Create signature and input example\n",
        "    signature = infer_signature(X_train_df, y_pred_df)\n",
        "    input_example = X_train_df.head(1)\n",
        "    \n",
        "    # Save and log model (like XGBoost example)\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        local_model_path = os.path.join(tmpdir, \"model\")\n",
        "        \n",
        "        mlflow.pytorch.save_model(\n",
        "            model,\n",
        "            local_model_path,\n",
        "            signature=signature,\n",
        "            input_example=input_example\n",
        "        )\n",
        "        \n",
        "        mlflow.log_artifacts(local_model_path, artifact_path=\"model\")\n",
        "        print(\"Model artifacts logged successfully!\")\n",
        "    \n",
        "    return all_metrics\n",
        "\n",
        "\n",
        "def create_sample_payload(X_test, y_test, model):\n",
        "    \"\"\"Create realistic sample prediction payload.\"\"\"\n",
        "    # Get a sample\n",
        "    sample_idx = 0\n",
        "    sample = X_test[sample_idx]\n",
        "    actual_digit = y_test[sample_idx]\n",
        "    \n",
        "    # Get model prediction (raw logits - what the deployed model will return)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        sample_tensor = torch.tensor(sample, dtype=torch.float32).unsqueeze(0)\n",
        "        logits = model(sample_tensor).numpy()[0]  # Shape: (10,) - raw scores\n",
        "        predicted_digit = int(logits.argmax())  # Convert to predicted class\n",
        "    \n",
        "    # Create feature dict\n",
        "    features = {f\"pixel_{i}\": float(sample[i]) for i in range(len(sample))}\n",
        "    \n",
        "    return {\n",
        "        \"features\": features,\n",
        "        \"actual_digit\": int(actual_digit),\n",
        "        \"predicted_digit\": predicted_digit,\n",
        "        \"raw_logits\": logits.tolist()  # Include raw scores for reference\n",
        "    }\n",
        "\n",
        "\n",
        "def register_model(client: MlflowClient, model_name: str, run_id: str, experiment_id: str):\n",
        "    \"\"\"Register model in MLflow Model Registry.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"REGISTERING MODEL\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    model_uri = f\"runs:/{run_id}/model\"\n",
        "    \n",
        "    # Create registered model if it doesn't exist\n",
        "    try:\n",
        "        client.get_registered_model(model_name)\n",
        "        print(f\"Model '{model_name}' already exists in registry\")\n",
        "    except Exception:\n",
        "        try:\n",
        "            client.create_registered_model(model_name)\n",
        "            print(f\"Created registered model: {model_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not create registered model: {e}\")\n",
        "    \n",
        "    # Create model version\n",
        "    try:\n",
        "        result = client.create_model_version(\n",
        "            name=model_name,\n",
        "            source=model_uri,\n",
        "            run_id=run_id\n",
        "        )\n",
        "        print(f\"Model version registered successfully!\")\n",
        "        print(f\"   Model Name: {model_name}\")\n",
        "        print(f\"   Version: {result.version}\")\n",
        "        print(f\"   Run ID: {run_id}\")\n",
        "        return result.version\n",
        "    except Exception as e:\n",
        "        print(f\"Model registration failed (model still usable via run URI): {e}\")\n",
        "        print(f\"   You can deploy using: mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def print_deployment_info(run_id: str, experiment_id: str, sample_payload: dict):\n",
        "    \"\"\"Print deployment instructions and sample payloads.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    print(f\"\\nRun Information:\")\n",
        "    print(f\"  Run ID: {run_id}\")\n",
        "    print(f\"  Experiment ID: {experiment_id}\")\n",
        "    print(f\"  Model URI: mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"DEPLOYMENT PAYLOAD (deploy-model API)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    deploy_payload = {\n",
        "        \"serve_name\": \"mnist-pytorch-classifier\",\n",
        "        \"model_uri\": f\"mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\",\n",
        "        \"env\": \"local\",\n",
        "        \"cores\": 2,\n",
        "        \"memory\": 4,\n",
        "        \"node_capacity\": \"spot\",\n",
        "        \"min_replicas\": 1,\n",
        "        \"max_replicas\": 3\n",
        "    }\n",
        "    \n",
        "    print(json.dumps(deploy_payload, indent=2))\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"SAMPLE PREDICTION PAYLOAD (first 10 pixels shown)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Show only first 10 pixels for brevity\n",
        "    sample_features = {k: v for i, (k, v) in enumerate(sample_payload[\"features\"].items()) if i < 10}\n",
        "    sample_features[\"...\"] = \"... (784 pixels total)\"\n",
        "    \n",
        "    predict_payload = {\n",
        "        \"features\": sample_features\n",
        "    }\n",
        "    \n",
        "    print(json.dumps(predict_payload, indent=2))\n",
        "    \n",
        "    print(f\"\\nExpected Output (Raw Logits):\")\n",
        "    print(f\"  Actual Digit: {sample_payload['actual_digit']}\")\n",
        "    print(f\"  Predicted Digit: {sample_payload['predicted_digit']} (argmax of logits)\")\n",
        "    print(f\"\\n  Model returns raw logits (10 scores, one per digit):\")\n",
        "    print(f\"  To get predicted digit: argmax(scores)\")\n",
        "    print(f\"  To get probabilities: softmax(scores)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Train PyTorch MNIST Classification Model\")\n",
        "    parser.add_argument(\n",
        "        \"--mlflow-uri\",\n",
        "        default=\"http://darwin-mlflow-lib.darwin.svc.cluster.local:8080\",\n",
        "        help=\"MLflow tracking URI\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--username\",\n",
        "        default=\"abc@gmail.com\",\n",
        "        help=\"MLflow username\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--password\",\n",
        "        default=\"password\",\n",
        "        help=\"MLflow password\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--experiment-name\",\n",
        "        default=\"mnist_pytorch_classification\",\n",
        "        help=\"MLflow experiment name\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model-name\",\n",
        "        default=\"MNISTPyTorchClassifier\",\n",
        "        help=\"Registered model name\"\n",
        "    )\n",
        "    \n",
        "    args, _ = parser.parse_known_args()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"MNIST DIGIT CLASSIFICATION WITH PYTORCH\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    \n",
        "    # Setup MLflow\n",
        "    client = setup_mlflow(args.mlflow_uri, args.username, args.password)\n",
        "    set_experiment(experiment_name=args.experiment_name)\n",
        "    print(f\"Experiment: {args.experiment_name}\")\n",
        "    \n",
        "    # Load data\n",
        "    X_train, X_test, y_train, y_test = load_and_prepare_data()\n",
        "    \n",
        "    # Define hyperparameters\n",
        "    hyperparams = {\n",
        "        \"epochs\": 20,\n",
        "        \"batch_size\": 128,\n",
        "        \"learning_rate\": 0.001,\n",
        "        \"dropout\": 0.2\n",
        "    }\n",
        "    \n",
        "    # Start MLflow run\n",
        "    with mlflow.start_run(run_name=f\"pytorch_mnist_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
        "        # Train model\n",
        "        model, y_train_pred, y_test_pred = train_model(\n",
        "            X_train, y_train, X_test, y_test, hyperparams\n",
        "        )\n",
        "        \n",
        "        # Log to MLflow\n",
        "        metrics = log_to_mlflow(\n",
        "            model, X_train, y_train, X_test, y_test,\n",
        "            y_train_pred, y_test_pred, hyperparams\n",
        "        )\n",
        "        \n",
        "        # Get run information\n",
        "        run_id = mlflow.active_run().info.run_id\n",
        "        experiment_id = mlflow.active_run().info.experiment_id\n",
        "        \n",
        "        # Create sample payload\n",
        "        sample_payload = create_sample_payload(X_test, y_test, model)\n",
        "    \n",
        "    # Register model (outside of run context)\n",
        "    version = register_model(client, args.model_name, run_id, experiment_id)\n",
        "    \n",
        "    # Print deployment information\n",
        "    print_deployment_info(run_id, experiment_id, sample_payload)\n",
        "    \n",
        "    print(\"\\nScript completed successfully!\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
