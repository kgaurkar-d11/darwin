{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5358e833",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification with TensorFlow/Keras\n",
    "\n",
    "This script trains a neural network using TensorFlow/Keras for binary classification.\n",
    "\n",
    "**Dataset:** Breast Cancer Wisconsin (Diagnostic)\n",
    "- 569 samples of breast cancer biopsies\n",
    "- Target: Malignant (1) or Benign (0)\n",
    "\n",
    "**Features:**\n",
    "- 30 numeric features computed from digitized images\n",
    "- Mean, standard error, and worst values of cell nuclei characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5e335",
   "metadata": {},
   "source": [
    "%pip install 'tensorflow~=2.15.0' pandas numpy scikit-learn mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51304e23",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Reduce TensorFlow logging verbosity\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Disable GPU to prevent memory issues (use CPU only)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Limit TensorFlow threading to prevent resource exhaustion\n",
    "os.environ['TF_NUM_INTEROP_THREADS'] = '2'\n",
    "os.environ['TF_NUM_INTRAOP_THREADS'] = '2'\n",
    "\n",
    "# Now import TensorFlow (after environment variables are set)\n",
    "import tensorflow as tf\n",
    "\n",
    "# Additional runtime configuration for memory efficiency\n",
    "tf.config.threading.set_inter_op_parallelism_threads(2)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n",
    "\n",
    "# Verify TensorFlow is using CPU\n",
    "print(f\"GPU devices: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(\"TensorFlow configured for CPU-only execution\")\n",
    "\n",
    "# ============================================================================\n",
    "# Standard imports (after TensorFlow configuration)\n",
    "# ============================================================================\n",
    "import argparse\n",
    "import json\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# TensorFlow/Keras imports\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# MLflow imports\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from mlflow import set_tracking_uri, set_experiment\n",
    "from mlflow.client import MlflowClient\n",
    "from mlflow.models import ModelSignature\n",
    "from mlflow.types import Schema, TensorSpec\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ad26e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def setup_mlflow(mlflow_uri: str, username: str, password: str) -> MlflowClient:\n",
    "    \"\"\"Configure MLflow tracking and return client.\"\"\"\n",
    "    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = username\n",
    "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = password\n",
    "    \n",
    "    set_tracking_uri(mlflow_uri)\n",
    "    client = MlflowClient(mlflow_uri)\n",
    "    \n",
    "    print(f\"MLflow tracking URI: {mlflow_uri}\")\n",
    "    return client\n",
    "\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Load Breast Cancer dataset and prepare train/test splits.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"LOADING DATASET\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Load dataset\n",
    "    data = load_breast_cancer(as_frame=True)\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    \n",
    "    print(f\"Dataset: Breast Cancer Wisconsin\")\n",
    "    print(f\"Samples: {X.shape[0]:,}\")\n",
    "    print(f\"Features: {X.shape[1]}\")\n",
    "    print(f\"\\nFeature names (first 10):\")\n",
    "    for i, col in enumerate(X.columns[:10], 1):\n",
    "        print(f\"  {i}. {col}\")\n",
    "    print(f\"  ... and {X.shape[1] - 10} more\")\n",
    "    \n",
    "    print(f\"\\nTarget distribution:\")\n",
    "    print(f\"  Malignant (1): {(y == 1).sum()} samples\")\n",
    "    print(f\"  Benign (0): {(y == 0).sum()} samples\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert back to DataFrame to preserve column names\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
    "    \n",
    "    print(f\"\\nTrain samples: {X_train_scaled.shape[0]:,}\")\n",
    "    print(f\"Test samples: {X_test_scaled.shape[0]:,}\")\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, X.columns.tolist()\n",
    "\n",
    "\n",
    "def create_model(input_dim: int, hyperparams: dict):\n",
    "    \"\"\"Create a lightweight Keras neural network model.\"\"\"\n",
    "    # Using a smaller model architecture for memory efficiency\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(32, activation='relu', input_shape=(input_dim,)),\n",
    "        layers.Dropout(hyperparams['dropout']),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dropout(hyperparams['dropout']),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hyperparams['learning_rate']),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_test, y_test, hyperparams: dict):\n",
    "    \"\"\"Train TensorFlow/Keras model and return predictions.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TRAINING MODEL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"Hyperparameters:\")\n",
    "    for key, value in hyperparams.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model(X_train.shape[1], hyperparams)\n",
    "    \n",
    "    print(f\"\\nModel architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Early stopping callback\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\nTraining...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=hyperparams['epochs'],\n",
    "        batch_size=hyperparams['batch_size'],\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"Training completed!\")\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred_proba = model.predict(X_train).flatten()\n",
    "    y_test_pred_proba = model.predict(X_test).flatten()\n",
    "    \n",
    "    y_train_pred = (y_train_pred_proba > 0.5).astype(int)\n",
    "    y_test_pred = (y_test_pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    return model, y_train_pred, y_test_pred, y_train_pred_proba, y_test_pred_proba\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba, dataset_name=\"Test\"):\n",
    "    \"\"\"Calculate and return evaluation metrics.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    return {\n",
    "        f\"{dataset_name.lower()}_accuracy\": accuracy,\n",
    "        f\"{dataset_name.lower()}_precision\": precision,\n",
    "        f\"{dataset_name.lower()}_recall\": recall,\n",
    "        f\"{dataset_name.lower()}_f1\": f1,\n",
    "        f\"{dataset_name.lower()}_auc\": auc\n",
    "    }\n",
    "\n",
    "\n",
    "def log_to_mlflow(model, X_train, y_train, X_test, y_test, \n",
    "                  y_train_pred, y_test_pred, y_train_pred_proba, y_test_pred_proba, \n",
    "                  hyperparams, feature_names):\n",
    "    \"\"\"Log model, parameters, and metrics to MLflow using native TensorFlow flavor.\n",
    "    \n",
    "    NOTE: This uses native mlflow.tensorflow.save_model() with TensorSpec signature.\n",
    "    The runtime's SchemaExtractor uses the input_example (DataFrame) to extract\n",
    "    feature names for /schema, and Model.inference() converts feature dicts to\n",
    "    ordered arrays using the same feature order.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"LOGGING TO MLFLOW\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Log hyperparameters\n",
    "    for key, value in hyperparams.items():\n",
    "        mlflow.log_param(key, value)\n",
    "    \n",
    "    # Calculate and log metrics\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred, y_train_pred_proba, \"Train\")\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred, y_test_pred_proba, \"Test\")\n",
    "    all_metrics = {**train_metrics, **test_metrics}\n",
    "    \n",
    "    for metric_name, metric_value in all_metrics.items():\n",
    "        mlflow.log_metric(metric_name, metric_value)\n",
    "    \n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(f\"  Training Accuracy: {train_metrics['train_accuracy']:.4f}\")\n",
    "    print(f\"  Training AUC: {train_metrics['train_auc']:.4f}\")\n",
    "    print(f\"  Test Accuracy: {test_metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"  Test Precision: {test_metrics['test_precision']:.4f}\")\n",
    "    print(f\"  Test Recall: {test_metrics['test_recall']:.4f}\")\n",
    "    print(f\"  Test F1: {test_metrics['test_f1']:.4f}\")\n",
    "    print(f\"  Test AUC: {test_metrics['test_auc']:.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    print(f\"\\n  Confusion Matrix:\")\n",
    "    print(f\"  {cm}\")\n",
    "    \n",
    "    # Create TensorSpec signature (required by mlflow.tensorflow.save_model)\n",
    "    # The runtime will use input_example's column names for /schema\n",
    "    # IMPORTANT: The input tensor name must match Keras's input layer name\n",
    "    # For Sequential models starting with Dense, this is typically \"dense_input\"\n",
    "    num_features = len(feature_names)\n",
    "    input_spec = TensorSpec(np.dtype(np.float64), (-1, num_features), name=\"dense_input\")\n",
    "    output_spec = TensorSpec(np.dtype(np.float32), (-1, 1), name=\"predictions\")\n",
    "    signature = ModelSignature(\n",
    "        inputs=Schema([input_spec]), \n",
    "        outputs=Schema([output_spec])\n",
    "    )\n",
    "    \n",
    "    # IMPORTANT: Use DataFrame as input_example to preserve feature names!\n",
    "    # The runtime's SchemaExtractor extracts column names from this DataFrame\n",
    "    # for /schema endpoint and converts feature dicts to arrays for /predict\n",
    "    input_example = X_test.head(1)  # DataFrame with 30 named columns\n",
    "    \n",
    "    print(f\"\\n  Saving model with TensorSpec signature...\")\n",
    "    print(f\"  Input example shape: {input_example.shape}\")\n",
    "    print(f\"  Feature names preserved in input_example: {len(input_example.columns)}\")\n",
    "    \n",
    "    # Save and log model with native TensorFlow flavor\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        local_model_path = os.path.join(tmpdir, \"model\")\n",
    "        \n",
    "        # Save as native TensorFlow model\n",
    "        mlflow.tensorflow.save_model(\n",
    "            model,\n",
    "            local_model_path,\n",
    "            signature=signature,\n",
    "            input_example=input_example  # DataFrame preserves column names!\n",
    "        )\n",
    "        \n",
    "        mlflow.log_artifacts(local_model_path, artifact_path=\"model\")\n",
    "        print(\"Model artifacts logged successfully!\")\n",
    "        print(\"  - Using native mlflow.tensorflow flavor\")\n",
    "        print(\"  - Input example preserves feature names for /schema\")\n",
    "    \n",
    "    return all_metrics\n",
    "\n",
    "\n",
    "def create_sample_payload(X_test, y_test, model, feature_names):\n",
    "    \"\"\"Create realistic sample prediction payload.\"\"\"\n",
    "    # Get a sample\n",
    "    sample_idx = 0\n",
    "    sample = X_test.iloc[sample_idx]\n",
    "    actual_class = y_test.iloc[sample_idx]\n",
    "    \n",
    "    # Predict\n",
    "    predicted_proba = model.predict(sample.values.reshape(1, -1)).flatten()[0]\n",
    "    predicted_class = int(predicted_proba > 0.5)\n",
    "    \n",
    "    return {\n",
    "        \"features\": sample.to_dict(),\n",
    "        \"actual_class\": int(actual_class),\n",
    "        \"actual_label\": \"Malignant\" if actual_class == 1 else \"Benign\",\n",
    "        \"predicted_class\": predicted_class,\n",
    "        \"predicted_label\": \"Malignant\" if predicted_class == 1 else \"Benign\",\n",
    "        \"predicted_probability\": float(predicted_proba)\n",
    "    }\n",
    "\n",
    "\n",
    "def register_model(client: MlflowClient, model_name: str, run_id: str, experiment_id: str):\n",
    "    \"\"\"Register model in MLflow Model Registry.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"REGISTERING MODEL\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "    \n",
    "    # Create registered model if it doesn't exist\n",
    "    try:\n",
    "        client.get_registered_model(model_name)\n",
    "        print(f\"Model '{model_name}' already exists in registry\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            client.create_registered_model(model_name)\n",
    "            print(f\"Created registered model: {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not create registered model: {e}\")\n",
    "    \n",
    "    # Create model version\n",
    "    try:\n",
    "        result = client.create_model_version(\n",
    "            name=model_name,\n",
    "            source=model_uri,\n",
    "            run_id=run_id\n",
    "        )\n",
    "        print(f\"Model version registered successfully!\")\n",
    "        print(f\"   Model Name: {model_name}\")\n",
    "        print(f\"   Version: {result.version}\")\n",
    "        print(f\"   Run ID: {run_id}\")\n",
    "        return result.version\n",
    "    except Exception as e:\n",
    "        print(f\"Model registration failed (model still usable via run URI): {e}\")\n",
    "        print(f\"   You can deploy using: mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def print_deployment_info(run_id: str, experiment_id: str, sample_payload: dict):\n",
    "    \"\"\"Print deployment instructions and sample payloads.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nRun Information:\")\n",
    "    print(f\"  Run ID: {run_id}\")\n",
    "    print(f\"  Experiment ID: {experiment_id}\")\n",
    "    print(f\"  Model URI: mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DEPLOYMENT PAYLOAD (deploy-model API)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    deploy_payload = {\n",
    "        \"serve_name\": \"breast-cancer-tensorflow-classifier\",\n",
    "        \"model_uri\": f\"mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\",\n",
    "        \"env\": \"local\",\n",
    "        \"cores\": 2,\n",
    "        \"memory\": 4,\n",
    "        \"node_capacity\": \"spot\",\n",
    "        \"min_replicas\": 1,\n",
    "        \"max_replicas\": 3\n",
    "    }\n",
    "    \n",
    "    print(json.dumps(deploy_payload, indent=2))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SAMPLE PREDICTION PAYLOAD (first 5 features shown)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show only first 5 features for brevity\n",
    "    sample_features = {k: v for i, (k, v) in enumerate(sample_payload[\"features\"].items()) if i < 5}\n",
    "    sample_features[\"...\"] = \"... (30 features total)\"\n",
    "    \n",
    "    predict_payload = {\n",
    "        \"features\": sample_features\n",
    "    }\n",
    "    \n",
    "    print(json.dumps(predict_payload, indent=2))\n",
    "    \n",
    "    print(f\"\\nExpected Output:\")\n",
    "    print(f\"  Actual: {sample_payload['actual_label']} (class {sample_payload['actual_class']})\")\n",
    "    print(f\"  Model Prediction: {sample_payload['predicted_label']} (class {sample_payload['predicted_class']})\")\n",
    "    print(f\"  Probability: {sample_payload['predicted_probability']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813b96c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Train TensorFlow Breast Cancer Classification Model\")\n",
    "    parser.add_argument(\n",
    "        \"--mlflow-uri\",\n",
    "        default=\"http://darwin-mlflow-lib.darwin.svc.cluster.local:8080\",\n",
    "        help=\"MLflow tracking URI\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--username\",\n",
    "        default=\"abc@gmail.com\",\n",
    "        help=\"MLflow username\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--password\",\n",
    "        default=\"password\",\n",
    "        help=\"MLflow password\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--experiment-name\",\n",
    "        default=\"breast_cancer_tensorflow_classification\",\n",
    "        help=\"MLflow experiment name\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--model-name\",\n",
    "        default=\"BreastCancerTensorFlowClassifier\",\n",
    "        help=\"Registered model name\"\n",
    "    )\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"BREAST CANCER CLASSIFICATION WITH TENSORFLOW/KERAS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # Setup MLflow\n",
    "    client = setup_mlflow(args.mlflow_uri, args.username, args.password)\n",
    "    set_experiment(experiment_name=args.experiment_name)\n",
    "    print(f\"Experiment: {args.experiment_name}\")\n",
    "    \n",
    "    # Load data\n",
    "    X_train, X_test, y_train, y_test, feature_names = load_and_prepare_data()\n",
    "    \n",
    "    # Define hyperparameters\n",
    "    hyperparams = {\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 32,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    "    \n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run(run_name=f\"tensorflow_breast_cancer_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "        # Train model\n",
    "        model, y_train_pred, y_test_pred, y_train_pred_proba, y_test_pred_proba = train_model(\n",
    "            X_train, y_train, X_test, y_test, hyperparams\n",
    "        )\n",
    "        \n",
    "        # Log to MLflow\n",
    "        metrics = log_to_mlflow(\n",
    "            model, X_train, y_train, X_test, y_test,\n",
    "            y_train_pred, y_test_pred, y_train_pred_proba, y_test_pred_proba,\n",
    "            hyperparams, feature_names\n",
    "        )\n",
    "        \n",
    "        # Get run information\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        experiment_id = mlflow.active_run().info.experiment_id\n",
    "        \n",
    "        # Create sample payload\n",
    "        sample_payload = create_sample_payload(X_test, y_test, model, feature_names)\n",
    "    \n",
    "    # Register model (outside of run context)\n",
    "    version = register_model(client, args.model_name, run_id, experiment_id)\n",
    "    \n",
    "    # Print deployment information\n",
    "    print_deployment_info(run_id, experiment_id, sample_payload)\n",
    "    \n",
    "    print(\"\\nScript completed successfully!\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
