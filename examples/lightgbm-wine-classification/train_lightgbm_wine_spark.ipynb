{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Wine Quality Classification: Spark Data Processing + LightGBM Training\n",
        "\n",
        "This example demonstrates a hybrid approach using **Spark for data processing** and **native LightGBM for model training**.\n",
        "\n",
        "## Architecture\n",
        "\n",
        "- **Data Processing**: PySpark for distributed ETL operations (scales to large datasets)\n",
        "- **Training**: Native LightGBM (efficient gradient boosting on driver)\n",
        "- **Model Logging**: MLflow lightgbm flavor (reliable and compatible)\n",
        "\n",
        "## Execution Modes\n",
        "\n",
        "This notebook supports two execution modes:\n",
        "- **Darwin Cluster Mode**: Uses Darwin SDK with Ray for distributed Spark processing\n",
        "- **Local Mode**: Uses local Spark session for development/testing\n",
        "\n",
        "## Dataset\n",
        "\n",
        "- **Name**: Wine Quality Dataset\n",
        "- **Samples**: 178 wine samples\n",
        "- **Target**: Wine class (0, 1, 2) - three different cultivars\n",
        "- **Type**: Multi-class Classification\n",
        "\n",
        "## Model\n",
        "\n",
        "- **Framework**: Native LightGBM\n",
        "- **Data Processing**: PySpark\n",
        "- **Objective**: Multi-class classification\n",
        "\n",
        "## Features\n",
        "\n",
        "The dataset includes 13 physicochemical properties:\n",
        "- `alcohol`: Alcohol content\n",
        "- `malic_acid`: Malic acid content\n",
        "- `ash`: Ash content\n",
        "- `alcalinity_of_ash`: Alcalinity of ash\n",
        "- `magnesium`: Magnesium content\n",
        "- `total_phenols`: Total phenols\n",
        "- `flavanoids`: Flavanoids content\n",
        "- `nonflavanoid_phenols`: Non-flavanoid phenols\n",
        "- `proanthocyanins`: Proanthocyanins content\n",
        "- `color_intensity`: Color intensity\n",
        "- `hue`: Hue\n",
        "- `od280/od315_of_diluted_wines`: OD280/OD315 ratio\n",
        "- `proline`: Proline content\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- Spark handles data loading, transformation, and splitting (can scale to big data)\n",
        "- Native LightGBM handles model training (efficient and fast)\n",
        "- Model logged using `mlflow.lightgbm` flavor (works with any MLflow server)\n",
        "- Fast model loading at serving time (no Spark dependencies needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix pyOpenSSL/cryptography compatibility issue first\n",
        "%pip install --upgrade pyOpenSSL cryptography\n",
        "\n",
        "# Install main dependencies (pin MLflow to match server version)\n",
        "%pip install lightgbm pandas numpy scikit-learn mlflow==2.12.2 pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import json\n",
        "import tempfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# LightGBM imports\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Spark imports (for data processing only)\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# MLflow imports\n",
        "import mlflow\n",
        "import mlflow.lightgbm\n",
        "from mlflow import set_tracking_uri, set_experiment\n",
        "from mlflow.client import MlflowClient\n",
        "from mlflow.models import infer_signature\n",
        "\n",
        "# Scikit-learn imports (for loading dataset and metrics)\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Darwin SDK imports (optional - only available on Darwin cluster)\n",
        "DARWIN_SDK_AVAILABLE = False\n",
        "try:\n",
        "    import ray\n",
        "    from darwin import init_spark_with_configs, stop_spark\n",
        "    DARWIN_SDK_AVAILABLE = True\n",
        "    print(\"Darwin SDK available - will use distributed Spark on Darwin cluster\")\n",
        "except ImportError as e:\n",
        "    print(f\"Darwin SDK not available: {e}\")\n",
        "    print(\"Running in LOCAL mode - will use local Spark session\")\n",
        "except AttributeError as e:\n",
        "    if \"X509_V_FLAG\" in str(e) or \"lib\" in str(e):\n",
        "        print(\"=\" * 80)\n",
        "        print(\"ERROR: pyOpenSSL/cryptography version conflict detected!\")\n",
        "        print(\"Please run the following in a cell before importing:\")\n",
        "        print(\"  %pip install --upgrade pyOpenSSL cryptography\")\n",
        "        print(\"Then restart the kernel and try again.\")\n",
        "        print(\"=\" * 80)\n",
        "        raise\n",
        "    else:\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def initialize_spark():\n",
        "    \"\"\"Initialize Spark session for data processing.\n",
        "    \n",
        "    Uses Darwin SDK on cluster, local Spark otherwise.\n",
        "    Spark is used for distributed data processing (ETL, splitting).\n",
        "    Training is done with native LightGBM on the driver.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"INITIALIZING SPARK SESSION\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Base Spark configurations for data processing\n",
        "    spark_configs = {\n",
        "        \"spark.sql.execution.arrow.pyspark.enabled\": \"true\",\n",
        "        \"spark.sql.session.timeZone\": \"UTC\",\n",
        "        \"spark.sql.shuffle.partitions\": \"4\",\n",
        "        \"spark.default.parallelism\": \"4\",\n",
        "        \"spark.executor.memory\": \"1g\",\n",
        "        \"spark.executor.cores\": \"1\",\n",
        "        \"spark.driver.memory\": \"1g\",\n",
        "        \"spark.executor.instances\": \"2\",\n",
        "    }\n",
        "    \n",
        "    if DARWIN_SDK_AVAILABLE:\n",
        "        # Running on Darwin cluster - use distributed Spark via Ray\n",
        "        print(\"Mode: Darwin Cluster (Distributed)\")\n",
        "        ray.init()\n",
        "        spark = init_spark_with_configs(spark_configs=spark_configs)\n",
        "    else:\n",
        "        # Running locally - use local Spark session\n",
        "        print(\"Mode: Local Spark Session\")\n",
        "        builder = SparkSession.builder \\\n",
        "            .appName(\"Wine-Spark-DataProcessing\") \\\n",
        "            .master(\"local[*]\")\n",
        "        \n",
        "        for key, value in spark_configs.items():\n",
        "            builder = builder.config(key, value)\n",
        "        \n",
        "        spark = builder.getOrCreate()\n",
        "    \n",
        "    print(f\"Spark version: {spark.version}\")\n",
        "    print(f\"Application ID: {spark.sparkContext.applicationId}\")\n",
        "    \n",
        "    return spark\n",
        "\n",
        "\n",
        "def cleanup_spark(spark):\n",
        "    \"\"\"Stop Spark session properly based on environment.\"\"\"\n",
        "    print(\"\\nStopping Spark session...\")\n",
        "    if DARWIN_SDK_AVAILABLE:\n",
        "        stop_spark()\n",
        "    else:\n",
        "        spark.stop()\n",
        "    print(\"Spark session stopped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def setup_mlflow(mlflow_uri: str, username: str, password: str) -> MlflowClient:\n",
        "    \"\"\"Configure MLflow tracking and return client.\"\"\"\n",
        "    os.environ[\"MLFLOW_TRACKING_USERNAME\"] = username\n",
        "    os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = password\n",
        "    \n",
        "    set_tracking_uri(mlflow_uri)\n",
        "    client = MlflowClient(mlflow_uri)\n",
        "    \n",
        "    print(f\"MLflow tracking URI: {mlflow_uri}\")\n",
        "    return client\n",
        "\n",
        "\n",
        "def load_and_prepare_data(spark: SparkSession):\n",
        "    \"\"\"Load Wine dataset using Spark for processing, return pandas for training.\n",
        "    \n",
        "    Uses Spark for distributed data operations (can scale to large datasets).\n",
        "    Returns pandas DataFrames for LightGBM training.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"LOADING DATASET\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Load dataset\n",
        "    data = load_wine(as_frame=True)\n",
        "    pdf = data.data.copy()\n",
        "    pdf['label'] = data.target\n",
        "    \n",
        "    feature_names = data.feature_names\n",
        "    \n",
        "    print(f\"Dataset: Wine\")\n",
        "    print(f\"Samples: {len(pdf):,}\")\n",
        "    print(f\"Features: {len(feature_names)}\")\n",
        "    \n",
        "    print(f\"\\nFeature names:\")\n",
        "    for i, col_name in enumerate(feature_names, 1):\n",
        "        print(f\"  {i}. {col_name}\")\n",
        "    \n",
        "    print(f\"\\nTarget distribution:\")\n",
        "    for class_idx in range(3):\n",
        "        count = (pdf['label'] == class_idx).sum()\n",
        "        print(f\"  Class {class_idx}: {count} samples\")\n",
        "    \n",
        "    # Use Spark for distributed data splitting (demonstrates Spark processing)\n",
        "    print(\"\\nUsing Spark for distributed data splitting...\")\n",
        "    spark_df = spark.createDataFrame(pdf)\n",
        "    train_spark, test_spark = spark_df.randomSplit([0.8, 0.2], seed=42)\n",
        "    \n",
        "    # Collect to pandas for LightGBM training\n",
        "    print(\"Collecting to pandas for training...\")\n",
        "    train_pdf = train_spark.toPandas()\n",
        "    test_pdf = test_spark.toPandas()\n",
        "    \n",
        "    print(f\"\\nTrain samples: {len(train_pdf):,}\")\n",
        "    print(f\"Test samples: {len(test_pdf):,}\")\n",
        "    \n",
        "    return train_pdf, test_pdf, feature_names\n",
        "\n",
        "\n",
        "def train_model(train_pdf, test_pdf, hyperparams: dict, feature_names: list):\n",
        "    \"\"\"Train LightGBM model using native LightGBM.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING MODEL (Native LightGBM)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    print(\"Hyperparameters:\")\n",
        "    for key, value in hyperparams.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    \n",
        "    # Prepare data\n",
        "    X_train = train_pdf[feature_names].values\n",
        "    y_train = train_pdf[\"label\"].values\n",
        "    X_test = test_pdf[feature_names].values\n",
        "    y_test = test_pdf[\"label\"].values\n",
        "    \n",
        "    print(f\"\\nTraining samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
        "    \n",
        "    # Create LightGBM datasets\n",
        "    train_data = lgb.Dataset(X_train, label=y_train, feature_name=list(feature_names))\n",
        "    test_data = lgb.Dataset(X_test, label=y_test, feature_name=list(feature_names), reference=train_data)\n",
        "    \n",
        "    # LightGBM parameters\n",
        "    params = {\n",
        "        \"objective\": hyperparams.get(\"objective\", \"multiclass\"),\n",
        "        \"num_class\": hyperparams.get(\"num_class\", 3),\n",
        "        \"num_leaves\": hyperparams.get(\"num_leaves\", 31),\n",
        "        \"learning_rate\": hyperparams.get(\"learning_rate\", 0.05),\n",
        "        \"feature_fraction\": hyperparams.get(\"feature_fraction\", 0.9),\n",
        "        \"bagging_fraction\": hyperparams.get(\"bagging_fraction\", 0.8),\n",
        "        \"bagging_freq\": hyperparams.get(\"bagging_freq\", 5),\n",
        "        \"verbose\": -1,\n",
        "        \"seed\": 42,\n",
        "    }\n",
        "    \n",
        "    # Train model\n",
        "    print(\"\\nTraining LightGBM model...\")\n",
        "    model = lgb.train(\n",
        "        params,\n",
        "        train_data,\n",
        "        num_boost_round=hyperparams.get(\"num_iterations\", 100),\n",
        "        valid_sets=[train_data, test_data],\n",
        "        valid_names=[\"train\", \"test\"],\n",
        "    )\n",
        "    \n",
        "    print(\"Training completed!\")\n",
        "    \n",
        "    # Make predictions\n",
        "    train_proba = model.predict(X_train)\n",
        "    test_proba = model.predict(X_test)\n",
        "    train_pred = np.argmax(train_proba, axis=1)\n",
        "    test_pred = np.argmax(test_proba, axis=1)\n",
        "    \n",
        "    # Store predictions for metrics calculation\n",
        "    train_results = {\"y_true\": y_train, \"y_pred\": train_pred, \"proba\": train_proba}\n",
        "    test_results = {\"y_true\": y_test, \"y_pred\": test_pred, \"proba\": test_proba}\n",
        "    \n",
        "    return model, train_results, test_results\n",
        "\n",
        "\n",
        "def calculate_metrics(results: dict, dataset_name=\"Test\"):\n",
        "    \"\"\"Calculate evaluation metrics from prediction results.\"\"\"\n",
        "    y_true = results[\"y_true\"]\n",
        "    y_pred = results[\"y_pred\"]\n",
        "    \n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
        "    \n",
        "    return {\n",
        "        f\"{dataset_name.lower()}_accuracy\": accuracy,\n",
        "        f\"{dataset_name.lower()}_precision\": precision,\n",
        "        f\"{dataset_name.lower()}_recall\": recall,\n",
        "        f\"{dataset_name.lower()}_f1\": f1\n",
        "    }\n",
        "\n",
        "\n",
        "def log_to_mlflow(model, train_results, test_results, hyperparams, feature_names, sample_input):\n",
        "    \"\"\"Log LightGBM model, parameters, and metrics to MLflow.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"LOGGING TO MLFLOW\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Log hyperparameters\n",
        "    for key, value in hyperparams.items():\n",
        "        mlflow.log_param(key, value)\n",
        "    \n",
        "    # Log training framework info\n",
        "    mlflow.log_param(\"training_framework\", \"lightgbm\")\n",
        "    mlflow.log_param(\"data_processing\", \"spark\")\n",
        "    \n",
        "    # Calculate and log metrics\n",
        "    train_metrics = calculate_metrics(train_results, dataset_name=\"Train\")\n",
        "    test_metrics = calculate_metrics(test_results, dataset_name=\"Test\")\n",
        "    all_metrics = {**train_metrics, **test_metrics}\n",
        "    \n",
        "    for metric_name, metric_value in all_metrics.items():\n",
        "        mlflow.log_metric(metric_name, metric_value)\n",
        "    \n",
        "    print(\"\\nModel Performance:\")\n",
        "    print(f\"  Training Accuracy: {train_metrics['train_accuracy']:.4f}\")\n",
        "    print(f\"  Training F1: {train_metrics['train_f1']:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_metrics['test_accuracy']:.4f}\")\n",
        "    print(f\"  Test Precision: {test_metrics['test_precision']:.4f}\")\n",
        "    print(f\"  Test Recall: {test_metrics['test_recall']:.4f}\")\n",
        "    print(f\"  Test F1: {test_metrics['test_f1']:.4f}\")\n",
        "    \n",
        "    # Print confusion matrix\n",
        "    cm = confusion_matrix(test_results[\"y_true\"], test_results[\"y_pred\"])\n",
        "    print(f\"\\n  Confusion Matrix:\")\n",
        "    print(f\"  {cm}\")\n",
        "    \n",
        "    # Log model using mlflow.lightgbm\n",
        "    model_logged = False\n",
        "    print(\"\\nSaving model artifacts...\")\n",
        "    try:\n",
        "        # Create signature\n",
        "        sample_output = pd.DataFrame({\"prediction\": [0]})\n",
        "        signature = infer_signature(sample_input, sample_output)\n",
        "        \n",
        "        # Log LightGBM model\n",
        "        print(\"  Logging to MLflow using lightgbm flavor...\")\n",
        "        mlflow.lightgbm.log_model(\n",
        "            lgb_model=model,\n",
        "            artifact_path=\"model\",\n",
        "            signature=signature,\n",
        "            input_example=sample_input\n",
        "        )\n",
        "        \n",
        "        model_logged = True\n",
        "        print(\"Model artifacts logged successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not log model artifacts: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        print(\"Metrics and parameters were logged successfully.\")\n",
        "    \n",
        "    # Store references for later use\n",
        "    all_metrics[\"_native_model\"] = model\n",
        "    all_metrics[\"_model_logged\"] = model_logged\n",
        "    \n",
        "    return all_metrics\n",
        "\n",
        "\n",
        "def register_model(client: MlflowClient, model_name: str, run_id: str, experiment_id: str):\n",
        "    \"\"\"Register model in MLflow Model Registry.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"REGISTERING MODEL\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    model_uri = f\"runs:/{run_id}/model\"\n",
        "    \n",
        "    # Create registered model if it doesn't exist\n",
        "    try:\n",
        "        client.get_registered_model(model_name)\n",
        "        print(f\"Model '{model_name}' already exists in registry\")\n",
        "    except Exception:\n",
        "        try:\n",
        "            client.create_registered_model(model_name)\n",
        "            print(f\"Created registered model: {model_name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not create registered model: {e}\")\n",
        "    \n",
        "    # Create model version\n",
        "    try:\n",
        "        result = client.create_model_version(\n",
        "            name=model_name,\n",
        "            source=model_uri,\n",
        "            run_id=run_id\n",
        "        )\n",
        "        print(f\"Model version registered successfully!\")\n",
        "        print(f\"   Model Name: {model_name}\")\n",
        "        print(f\"   Version: {result.version}\")\n",
        "        print(f\"   Run ID: {run_id}\")\n",
        "        return result.version\n",
        "    except Exception as e:\n",
        "        print(f\"Model registration failed (model still usable via run URI): {e}\")\n",
        "        print(f\"   You can deploy using: mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def load_model_and_predict(sample_data: pd.DataFrame, native_model=None, feature_names=None):\n",
        "    \"\"\"Load model and run prediction on driver.\n",
        "    \n",
        "    Args:\n",
        "        sample_data: Pandas DataFrame with feature data\n",
        "        native_model: The native LightGBM booster model\n",
        "        feature_names: List of feature column names\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"LOADING MODEL AND RUNNING PREDICTION\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    if native_model is None:\n",
        "        print(\"Error: No model provided\")\n",
        "        return None\n",
        "    \n",
        "    print(\"Using in-memory model for prediction\")\n",
        "    \n",
        "    # Convert to numpy array for prediction\n",
        "    X = sample_data[feature_names].values if feature_names else sample_data.values\n",
        "    \n",
        "    # Run prediction using native LightGBM booster\n",
        "    probabilities = native_model.predict(X)\n",
        "    predictions = np.argmax(probabilities, axis=1)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"SAMPLE PREDICTION RESULTS\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"\\nInput features:\")\n",
        "    for col_name in sample_data.columns:\n",
        "        print(f\"  {col_name}: {sample_data[col_name].iloc[0]:.4f}\")\n",
        "    \n",
        "    print(f\"\\nClass Probabilities:\")\n",
        "    for i, prob in enumerate(probabilities[0]):\n",
        "        print(f\"  Class {i}: {prob:.4f}\")\n",
        "    print(f\"\\nPredicted Class: {predictions[0]}\")\n",
        "    \n",
        "    return predictions, probabilities\n",
        "\n",
        "\n",
        "def print_deployment_info(run_id: str, experiment_id: str, model_name: str, model_version: str):\n",
        "    \"\"\"Print deployment instructions and sample payloads.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    print(f\"\\nRun Information:\")\n",
        "    print(f\"  Run ID: {run_id}\")\n",
        "    print(f\"  Experiment ID: {experiment_id}\")\n",
        "    print(f\"  Model URI (run): runs:/{run_id}/model\")\n",
        "    if model_version:\n",
        "        print(f\"  Model URI (registry): models:/{model_name}/{model_version}\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"DEPLOYMENT PAYLOAD (deploy-model API)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    deploy_payload = {\n",
        "        \"serve_name\": \"wine-lightgbm-spark-classifier\",\n",
        "        \"model_uri\": f\"mlflow-artifacts:/{experiment_id}/{run_id}/artifacts/model\",\n",
        "        \"env\": \"local\",\n",
        "        \"cores\": 2,\n",
        "        \"memory\": 4,\n",
        "        \"node_capacity\": \"spot\",\n",
        "        \"min_replicas\": 1,\n",
        "        \"max_replicas\": 3\n",
        "    }\n",
        "    \n",
        "    print(json.dumps(deploy_payload, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Train Wine Classification Model (Spark data processing + LightGBM training)\")\n",
        "    parser.add_argument(\n",
        "        \"--mlflow-uri\",\n",
        "        default=\"http://darwin-mlflow-lib.darwin.svc.cluster.local:8080\",\n",
        "        help=\"MLflow tracking URI\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--username\",\n",
        "        default=\"abc@gmail.com\",\n",
        "        help=\"MLflow username\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--password\",\n",
        "        default=\"password\",\n",
        "        help=\"MLflow password\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--experiment-name\",\n",
        "        default=\"wine_spark_lightgbm_classification\",\n",
        "        help=\"MLflow experiment name\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model-name\",\n",
        "        default=\"WineLightGBMClassifier\",\n",
        "        help=\"Registered model name\"\n",
        "    )\n",
        "    \n",
        "    args, _ = parser.parse_known_args()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"WINE CLASSIFICATION: SPARK DATA PROCESSING + LIGHTGBM TRAINING\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    \n",
        "    # Initialize Spark for data processing\n",
        "    spark = initialize_spark()\n",
        "    \n",
        "    # Setup MLflow\n",
        "    client = setup_mlflow(args.mlflow_uri, args.username, args.password)\n",
        "    set_experiment(experiment_name=args.experiment_name)\n",
        "    print(f\"Experiment: {args.experiment_name}\")\n",
        "    \n",
        "    # Load and prepare data using Spark (returns pandas DataFrames)\n",
        "    train_pdf, test_pdf, feature_names = load_and_prepare_data(spark)\n",
        "    \n",
        "    # Define hyperparameters\n",
        "    hyperparams = {\n",
        "        \"objective\": \"multiclass\",\n",
        "        \"num_class\": 3,\n",
        "        \"num_leaves\": 31,\n",
        "        \"learning_rate\": 0.05,\n",
        "        \"feature_fraction\": 0.9,\n",
        "        \"bagging_fraction\": 0.8,\n",
        "        \"bagging_freq\": 5,\n",
        "        \"num_iterations\": 100,\n",
        "    }\n",
        "    \n",
        "    # Get sample input for MLflow logging\n",
        "    sample_input = train_pdf[feature_names].head(1)\n",
        "    \n",
        "    # Start MLflow run\n",
        "    with mlflow.start_run(run_name=f\"lightgbm_wine_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
        "        # Train LightGBM model\n",
        "        model, train_results, test_results = train_model(\n",
        "            train_pdf, test_pdf, hyperparams, feature_names\n",
        "        )\n",
        "        \n",
        "        # Log to MLflow\n",
        "        metrics = log_to_mlflow(\n",
        "            model, train_results, test_results, hyperparams, feature_names, sample_input\n",
        "        )\n",
        "        \n",
        "        # Get run information\n",
        "        run_id = mlflow.active_run().info.run_id\n",
        "        experiment_id = mlflow.active_run().info.experiment_id\n",
        "    \n",
        "    # Register model (outside of run context) - only if artifacts were logged\n",
        "    model_version = None\n",
        "    if metrics.get(\"_model_logged\", False):\n",
        "        model_version = register_model(client, args.model_name, run_id, experiment_id)\n",
        "    else:\n",
        "        print(\"\\nSkipping model registration (artifacts not logged to MLflow)\")\n",
        "    \n",
        "    # Demo prediction with LightGBM model\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"SAMPLE PREDICTION\")\n",
        "    print(\"=\" * 80)\n",
        "    sample_pdf = test_pdf[feature_names].head(1)\n",
        "    native_model = metrics.get(\"_native_model\")\n",
        "    predictions, probabilities = load_model_and_predict(sample_pdf, native_model=native_model, feature_names=feature_names)\n",
        "    \n",
        "    # Get actual value for comparison\n",
        "    actual_value = test_pdf[\"label\"].iloc[0]\n",
        "    print(f\"\\nActual Class: {int(actual_value)}\")\n",
        "    print(f\"Prediction Correct: {predictions[0] == actual_value}\")\n",
        "    \n",
        "    # Print deployment information\n",
        "    print_deployment_info(run_id, experiment_id, args.model_name, model_version)\n",
        "    \n",
        "    # Cleanup: Stop Spark session\n",
        "    cleanup_spark(spark)\n",
        "    \n",
        "    print(\"\\nScript completed successfully!\")\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
