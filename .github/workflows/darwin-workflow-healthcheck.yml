name: Darwin Workflow - Health Check

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'darwin-workflow/**'
      - 'init.sh'
      - 'setup.sh'
      - 'start.sh'
      - 'services.yaml'
  workflow_dispatch:  # Allow manual triggering

jobs:
  health-check:
    runs-on: [self-hosted, Linux, X64, darwin]
    defaults:
      run:
        working-directory: .

    steps:
      - name: Runner identity (debug)
        run: |
          echo "Runner name: $RUNNER_NAME"
          echo "Runner OS: $RUNNER_OS"
          echo "Runner arch: $RUNNER_ARCH"
          hostname
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Clean up disk space
        run: |
          echo "ðŸ§¹ Cleaning up disk space before build..."
          echo "Current disk usage:"
          df -h
          echo ""
          echo "Cleaning up Docker resources..."
          docker system prune -a -f || true
          docker volume prune -f || true
          echo ""
          echo "Cleaning up apt cache..."
          sudo apt-get clean || true
          sudo rm -rf /var/lib/apt/lists/* || true
          echo ""
          echo "Disk usage after cleanup:"
          df -h
      - name: Install prerequisites
        run: |
          # Install kubectl
          KUBECTL_VERSION=$(curl -L -s https://dl.k8s.io/release/stable.txt)
          echo "Installing kubectl version: $KUBECTL_VERSION"
          curl -LO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          # Verify the download is actually a binary (not an error page)
          if ! file kubectl | grep -q "ELF\|executable"; then
            echo "âŒ Downloaded file is not a binary, retrying with direct URL..."
            rm -f kubectl
            curl -LO "https://storage.googleapis.com/kubernetes-release/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          fi
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/kubectl
          kubectl version --client
          # Install Helm
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
          helm version
          # Install Kind
          curl -Lo /tmp/kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
          chmod +x /tmp/kind
          sudo mv /tmp/kind /usr/local/bin/kind
          kind version
          # Install yq (required by init.sh)
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq
          yq --version
      - name: Initialize submodules
        run: |
          git submodule sync --recursive
          git submodule update --init --recursive --remote || true
      - name: Step 1 - Initialize configuration (init.sh)
        run: |
          echo "ðŸ“‹ Step 1: Running init.sh to configure services..."
          
          # Clean up any existing config to avoid overwrite prompt
          rm -f .setup/enabled-services.yaml
          
          # Answers (13 prompts total):
          # 1-7: compute, workspace, feature_store, mlflow, serve, catalog, chronos (all n)
          # 8: workflow (y) - will auto-enable darwin-compute and darwin-cluster-manager as dependencies
          # 9: confirm (y)
          # 10: darwin sdk runtime (n)
          # 11: ray:2.37.0 (n)
          # 12: ray:2.53.0 (n)
          # 13: hermes-cli (n)
          # Use printf with explicit newlines and ensure stdin is properly closed
          printf "n\nn\nn\nn\nn\nn\nn\ny\ny\nn\nn\nn\nn\n" | ./init.sh || {
            echo "âŒ init.sh failed with exit code $?"
            echo "Checking if config was created..."
            if [ -f .setup/enabled-services.yaml ]; then
              echo "Config file exists, showing contents:"
              cat .setup/enabled-services.yaml
            else
              echo "Config file was not created"
            fi
            exit 1
          }
          
          echo "âœ… Configuration created by init.sh"
          cat .setup/enabled-services.yaml
      - name: Step 2 - Build images and setup cluster (setup.sh)
        run: |
          echo "ðŸ”¨ Step 2: Running setup.sh to build images and setup cluster..."
          # Clean up Docker before building to free space (GitHub Actions runners have limited disk space)
          echo "ðŸ§¹ Cleaning up Docker before build..."
          docker system prune -f || true
          docker image prune -f || true
          echo "Disk space before build:"
          df -h
          # Ensure ENV is set to local for cluster creation
          export ENV=local
          # Run setup.sh with auto-yes flag (it will auto-answer yes to cluster setup and clean build)
          # setup.sh will handle errors gracefully - if cluster creation fails but KUBECONFIG exists, it will continue
          ./setup.sh -y
          # Clean up unused images after build to free space for deployment
          echo "ðŸ§¹ Cleaning up unused Docker images after build..."
          docker image prune -f || true
          echo "Disk space after build:"
          df -h
      - name: Verify cluster is ready
        run: |
          echo "ðŸ” Verifying cluster status..."
          export KUBECONFIG=./kind/config/kindkubeconfig.yaml
          
          if [ ! -f "$KUBECONFIG" ]; then
            echo "âŒ KUBECONFIG not found, cluster may not be ready"
            exit 1
          fi
          
          # Wait for cluster to be ready
          max_attempts=30
          attempt=0
          while [ $attempt -lt $max_attempts ]; do
            if kubectl get nodes >/dev/null 2>&1; then
              echo "âœ… Cluster is accessible"
              kubectl get nodes
              break
            fi
            echo "Attempt $((attempt+1))/$max_attempts: Waiting for cluster..."
            sleep 5
            attempt=$((attempt+1))
          done
          
          if [ $attempt -eq $max_attempts ]; then
            echo "âŒ Cluster is not accessible"
            exit 1
          fi
      - name: Step 3 - Deploy to Kubernetes (start.sh)
        run: |
          echo "ðŸš€ Step 3: Running start.sh to deploy to Kubernetes..."
          export KUBECONFIG=./kind/config/kindkubeconfig.yaml
          
          # Source config.env if it exists
          if [ -f config.env ]; then
            set -o allexport
            source config.env
            set +o allexport
          fi
          
          # Verify cluster is accessible before deployment
          echo "ðŸ” Verifying cluster connectivity..."
          if ! kubectl get nodes >/dev/null 2>&1; then
            echo "âŒ Cluster is not accessible"
            exit 1
          fi
          
          # Run start.sh - it should fail if deployment fails
          if ! ./start.sh; then
            echo "âŒ start.sh failed, checking deployment status..."
            echo ""
            echo "Helm releases:"
            helm list -n darwin || true
            echo ""
            echo "All pods in darwin namespace:"
            kubectl get pods -n darwin || true
            echo ""
            echo "All resources in darwin namespace:"
            kubectl get all -n darwin || true
            echo ""
            echo "Helm release status:"
            helm status darwin -n darwin || true
            echo ""
            echo "Helm release history:"
            helm history darwin -n darwin || true
            exit 1
          fi
          
          # Verify deployment was successful
          echo "ðŸ” Verifying deployment..."
          if ! helm list -n darwin | grep -q darwin; then
            echo "âŒ Helm release 'darwin' not found after start.sh completed"
            exit 1
          fi
          
          echo "âœ… Deployment completed successfully"
      - name: Wait for darwin-workflow pod to be ready
        run: |
          echo "â³ Waiting for darwin-workflow pod to be ready..."
          export KUBECONFIG=./kind/config/kindkubeconfig.yaml
          
          max_attempts=60
          attempt=0
          while [ $attempt -lt $max_attempts ]; do
            # Check if pod exists and is ready
            if kubectl get pods -n darwin -l app.kubernetes.io/name=darwin-workflow 2>/dev/null | grep -q "Running\|1/1\|2/2"; then
              echo "âœ… darwin-workflow pod is ready"
              kubectl get pods -n darwin -l app.kubernetes.io/name=darwin-workflow
              break
            fi
            echo "Attempt $((attempt+1))/$max_attempts: Waiting for pod..."
            kubectl get pods -n darwin -l app.kubernetes.io/name=darwin-workflow || true
            sleep 5
            attempt=$((attempt+1))
          done
          
          if [ $attempt -eq $max_attempts ]; then
            echo "âŒ darwin-workflow pod did not become ready"
            echo "Pod status:"
            kubectl get pods -n darwin -l app.kubernetes.io/name=darwin-workflow || true
            echo "Pod logs:"
            kubectl logs -n darwin -l app.kubernetes.io/name=darwin-workflow --tail=50 || true
            exit 1
          fi
      - name: Verify Services Are Healthy (as per root README)
        run: |
          echo "âœ… Verifying services are healthy (as per root README)..."
          export KUBECONFIG=./kind/config/kindkubeconfig.yaml
          
          # Check all pods are running (as per README: kubectl get pods -n darwin)
          echo "ðŸ“¦ Checking all pods are running:"
          kubectl get pods -n darwin
          
          # Wait for ingress to be ready (if available)
          echo "â³ Waiting for ingress controller to be ready..."
          max_attempts=30
          attempt=0
          while [ $attempt -lt $max_attempts ]; do
            if kubectl get pods -n ingress-nginx 2>/dev/null | grep -q "Running"; then
              echo "âœ… Ingress controller is ready"
              break
            fi
            sleep 2
            attempt=$((attempt+1))
          done
          
          # Test health check via ingress (as per README: curl http://localhost/workflow/healthcheck)
          echo "ðŸ¥ Testing health check via ingress..."
          # Note: In CI, we may need to use port-forward instead if ingress isn't accessible
          # Try ingress first, fallback to port-forward
          
          # Start port-forward in background (as per README alternative: kubectl port-forward svc/darwin-workflow -n darwin 8001:8001)
          kubectl port-forward svc/darwin-workflow -n darwin 8001:8001 > /tmp/port-forward.log 2>&1 &
          PORT_FORWARD_PID=$!
          echo "Port-forward started with PID: $PORT_FORWARD_PID"
          
          # Wait for port-forward to be ready
          sleep 5
          
          # Test health check endpoint (as per README: curl http://localhost:8001/healthcheck)
          max_attempts=30
          attempt=0
          while [ $attempt -lt $max_attempts ]; do
            if curl -f -s http://localhost:8001/healthcheck > /dev/null 2>&1; then
              echo "âœ… Health check endpoint is accessible"
              break
            fi
            echo "Attempt $((attempt+1))/$max_attempts: Waiting for health check endpoint..."
            sleep 2
            attempt=$((attempt+1))
          done
          
          if [ $attempt -eq $max_attempts ]; then
            echo "âŒ Health check endpoint not accessible"
            echo "Port-forward logs:"
            cat /tmp/port-forward.log || true
            kill $PORT_FORWARD_PID 2>/dev/null || true
            exit 1
          fi
          
          # Test health check endpoint and verify response (as per README expected response)
          echo "Testing /healthcheck endpoint..."
          response=$(curl -s -w "\nHTTP_CODE:%{http_code}" http://localhost:8001/healthcheck)
          http_code=$(echo "$response" | grep "HTTP_CODE" | cut -d: -f2)
          body=$(echo "$response" | grep -v "HTTP_CODE")
          
          echo "HTTP Status Code: $http_code"
          echo "Response Body: $body"
          
          if [ "$http_code" != "200" ]; then
            echo "âŒ Health check returned HTTP $http_code, expected 200"
            kill $PORT_FORWARD_PID 2>/dev/null || true
            exit 1
          fi
          
          # Verify response structure matches README expected response
          python3 << EOF
          import json
          import sys
          
          try:
              data = json.loads('''$body''')
              required_fields = ['app_layer', 'core', 'db']
              missing_fields = [f for f in required_fields if f not in data]
              
              if missing_fields:
                  print(f"âŒ Missing required fields: {missing_fields}")
                  sys.exit(1)
              
              print("âœ… Health check response structure is valid")
              print(f"   app_layer: {data.get('app_layer')}")
              print(f"   core: {data.get('core')}")
              print(f"   db: {data.get('db')}")
              
              # Verify values match expected format from README
              if data.get('app_layer') != 'OK':
                  print(f"âš ï¸  app_layer is '{data.get('app_layer')}', expected 'OK'")
              
              if data.get('core') != 'OK':
                  print(f"âš ï¸  core is '{data.get('core')}', expected 'OK'")
              
              # db can be True/False (string or boolean)
              db_value = data.get('db')
              if db_value not in [True, False, 'True', 'False', 'true', 'false']:
                  print(f"âš ï¸  db value '{db_value}' is unexpected")
              
              print("\nâœ… Health check passed! Service is healthy (as per root README).")
          except json.JSONDecodeError as e:
              print(f"âŒ Invalid JSON response: {e}")
              sys.exit(1)
          EOF
          
          # Cleanup port-forward
          kill $PORT_FORWARD_PID 2>/dev/null || true
      - name: Cleanup
        if: always()
        run: |
          echo "ðŸ§¹ Cleaning up..."
          export KUBECONFIG=./kind/config/kindkubeconfig.yaml || true
          
          # Clean up Docker to free space (important for GitHub Actions runners)
          echo "Cleaning up Docker resources..."
          docker system prune -a -f || true
          docker volume prune -f || true
          
          # Kill any port-forwards
          pkill -f "kubectl port-forward" || true
          
          # Delete kind cluster if it exists
          if kind get clusters 2>/dev/null | grep -q kind; then
            echo "Deleting kind cluster..."
            kind delete cluster --name kind || true
          fi
          
          # Cleanup Docker resources
          docker system prune -f || true