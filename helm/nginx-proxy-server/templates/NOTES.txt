ğŸš€ Nginx Proxy Server has been deployed successfully!

ğŸ“‹ DEPLOYMENT INFO:
  Release Name: {{ .Release.Name }}
  Namespace: {{ .Release.Namespace }}
  Chart Version: {{ .Chart.Version }}
  App Version: {{ .Chart.AppVersion }}

ğŸ”— ACCESS INFORMATION:
{{- if .Values.ingress.enabled }}
  {{- if .Values.ingress.internal.enabled }}
  
  ğŸ  Internal Access:
    URL Pattern: http://<internal-alb>/{{ .Values.global.kubeClusterKey }}/{cluster-name}-{service}
    Example: http://<internal-alb>/{{ .Values.global.kubeClusterKey }}/id-test-jupyter
  {{- end }}
  {{- if .Values.ingress.external.enabled }}
  
  ğŸŒ External Access:
    URL Pattern: http://<external-alb>/{{ .Values.global.kubeClusterKey }}/{cluster-name}/{service}
    Example: http://<external-alb>/{{ .Values.global.kubeClusterKey }}/id-test-dashboard/
  {{- end }}
{{- else }}
  
  ğŸ”§ Service Access:
    Service: {{ include "nginx-proxy-server.fullname" . }}
    Port: {{ .Values.nginx.service.port }}
    
    # Port forward to test locally:
    kubectl port-forward svc/{{ include "nginx-proxy-server.fullname" . }} 8080:{{ .Values.nginx.service.port }}
    curl http://localhost:8080/{{ .Values.global.kubeClusterKey }}/id-test-jupyter
{{- end }}

ğŸ“Š SCALING INFO:
{{- if .Values.nginx.hpa.enabled }}
  Auto-scaling: Enabled
  Min Replicas: {{ .Values.nginx.hpa.minReplicas }}
  Max Replicas: {{ .Values.nginx.hpa.maxReplicas }}
  CPU Target: {{ .Values.nginx.hpa.targetCPUUtilizationPercentage }}%
  Memory Target: {{ .Values.nginx.hpa.targetMemoryUtilizationPercentage }}%
{{- else }}
  Static Replicas: {{ .Values.nginx.replicas | default 3 }}
{{- end }}

ğŸ¯ SUPPORTED SERVICES:
  â€¢ jupyter    (port 8888) - Jupyter Lab
  â€¢ dashboard  (port 8265) - Ray Dashboard  
  â€¢ sparkui    (port 4040) - Spark UI
  â€¢ vscode     (port 3000) - VS Code Server
  â€¢ metrics    (port 3000) - Grafana (special routing)
  â€¢ livy       (port 8998) - Livy Server
  â€¢ thrift     (port 10000) - Thrift Server
  â€¢ custom-1   (port 8001) - Custom Service 1
  â€¢ custom-2   (port 8002) - Custom Service 2
  â€¢ custom-3   (port 8003) - Custom Service 3

ğŸš€ QUICK START:
  1. Deploy a Ray cluster:
     helm install id-test ./charts/ray-cluster

  2. Access services:
     - Jupyter: /{{ .Values.global.kubeClusterKey }}/my-cluster-jupyter
     - Dashboard: /{{ .Values.global.kubeClusterKey }}/my-cluster-dashboard/
     - Metrics: /{{ .Values.global.kubeClusterKey }}/my-cluster-metrics/

ğŸ” MONITORING COMMANDS:
  # Check proxy status
  kubectl get pods -l app.kubernetes.io/name={{ include "nginx-proxy-server.name" . }}
  
  # View logs
  kubectl logs -l app.kubernetes.io/name={{ include "nginx-proxy-server.name" . }} -f
  
  # Test nginx config
  kubectl exec deployment/{{ include "nginx-proxy-server.fullname" . }} -- nginx -t
  
  # Check HPA status
  {{- if .Values.nginx.hpa.enabled }}
  kubectl get hpa {{ include "nginx-proxy-server.fullname" . }}
  {{- end }}

ğŸ“š DOCUMENTATION:
  For more information and troubleshooting:
  â€¢ Chart README: ./charts/nginx-proxy-server/README.md
  â€¢ Custom routing: Modify nginx-config.yaml template

ğŸ’¡ TIP: The proxy automatically routes to any Ray cluster using the pattern:
     /{{ .Values.global.kubeClusterKey }}/{cluster-name}-{service}
     No manual configuration required!
